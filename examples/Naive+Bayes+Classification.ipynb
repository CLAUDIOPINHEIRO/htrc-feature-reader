{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HTRC: Easy classification from HathiTrust collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from htrc import workset\n",
    "import pandas as pd\n",
    "from htrc_features import FeatureReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following two collections are sets of books about knitting and about sewing.\n",
    "\n",
    "I'm using functionality from the [HTRC Python SDK](https://github.com/htrc/HTRC-PythonSDK) to grab volume ids from each collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 106 books about knitting and 214 books about sewing\n"
     ]
    }
   ],
   "source": [
    "knitids = workset.load_hathitrust_collection('https://babel.hathitrust.org/cgi/mb?a=listis&c=1174943610')\n",
    "sewids = workset.load_hathitrust_collection('https://babel.hathitrust.org/cgi/mb?a=listis&c=973680817')\n",
    "print(\"We have %d books about knitting and %d books about sewing\" % (len(knitids), len(sewids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the new online loading, all you need are HathiTrust ids to load features for a file. e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLE IDS ['mdp.39015060818443', 'pst.000016693067', 'mdp.39015056877270', 'inu.39000004664442', 'nyp.33433006775112', 'nnc1.cu56639260', 'caia.ark:/13960/t5n88cm6c', 'umn.31951000482982z', 'inu.30000100583941', 'loc.ark:/13960/t47p9n50g'] \n",
      "TITLES\n",
      "A good yarn / Debbie Macomber.\n",
      "A handy knitting library / [by Marti, pseud.\n",
      "A history of hand knitting / Richard Rutt ; with foreword by Meg Swansen.\n",
      "A history of hand knitting / Richard Rutt.\n",
      "A manual of needlework, knitting and cutting out for evening continuation schools.\n",
      "A text-book of needlework, knitting and cutting out, with methods of teaching.\n",
      "A treatise on embroidery, crochet and knitting ... Edited by Miss Anna Grayson Ford [and others]. Comp. by George C. Perkins.\n",
      "America's knitting book. Illustrated by Marjorie Tweed, Alan Howe, and Lyle Braden.\n",
      "Anatolian knitting designs : Sivas stocking patterns / collected in an Istanbul shantytown by Betsy Harrell ; drawings by Betsy Harrell.\n",
      "Art needlework.\n"
     ]
    }
   ],
   "source": [
    "print(\"SAMPLE IDS\", knitids[:10], \"\\nTITLES\")\n",
    "fr = FeatureReader(ids=knitids[:10])\n",
    "for vol in fr.volumes():\n",
    "    print(vol.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Use: classification\n",
    "\n",
    "Collect the token frequencies for each of the knitting and sewing books, and concatenate those to a single `df` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_clean_tokens(vol):\n",
    "    if vol.language != 'eng':\n",
    "        raise\n",
    "    tl = (vol.tokenlist(case=False, pages=False, pos=False)\n",
    "                .reset_index('section', drop=True)\n",
    "                .reset_index()\n",
    "           )\n",
    "    tl['vol'] = vol.id\n",
    "    return tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 35s, sys: 1.13 s, total: 1min 36s\n",
      "Wall time: 2min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fr = FeatureReader(ids=knitids+sewids)\n",
    "dfs = []\n",
    "for vol in fr.volumes():\n",
    "    dfs.append(get_clean_tokens(vol))\n",
    "df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>index</th>\n",
       "      <th>lowercase</th>\n",
       "      <th>section</th>\n",
       "      <th>vol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6534</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>paraffin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>inu.30000108723713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>illustrator</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mdp.39015061342401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3701</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>patfoftduca</td>\n",
       "      <td>NaN</td>\n",
       "      <td>uc1.$b243421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>academy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wu.89055826556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2563</th>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>were</td>\n",
       "      <td>NaN</td>\n",
       "      <td>uma.ark:/13960/t2n614s14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      count  index    lowercase section                       vol\n",
       "6534    1.0    NaN     paraffin     NaN        inu.30000108723713\n",
       "514     1.0    NaN  illustrator     NaN        mdp.39015061342401\n",
       "3701    1.0    NaN  patfoftduca     NaN              uc1.$b243421\n",
       "1047    1.0    NaN      academy     NaN            wu.89055826556\n",
       "2563   29.0    NaN         were     NaN  uma.ark:/13960/t2n614s14"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trim tokens to words that show up at least 400 times, are entirely alphabetical, include at least one lowercase character, and are more than 2 characters long.\n",
    "\n",
    "Then, convert the long vol/token/count DataFrame to a wide one, where rows are documents, columns are tokens, and the cells show the count of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>lowercase</th>\n",
       "      <th>abbreviations</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>about</th>\n",
       "      <th>above</th>\n",
       "      <th>accessories</th>\n",
       "      <th>according</th>\n",
       "      <th>account</th>\n",
       "      <th>accurate</th>\n",
       "      <th>accurately</th>\n",
       "      <th>...</th>\n",
       "      <th>your</th>\n",
       "      <th>yourself</th>\n",
       "      <th>zigzag</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zippers</th>\n",
       "      <th>ﬁne</th>\n",
       "      <th>ﬁnish</th>\n",
       "      <th>ﬁnished</th>\n",
       "      <th>ﬁrst</th>\n",
       "      <th>ﬂat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vol</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aeu.ark:/13960/t3126jv35</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aeu.ark:/13960/t5t72tb3n</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caia.ark:/13960/t03x9j98z</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caia.ark:/13960/t13n3fp1h</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caia.ark:/13960/t2r50x34b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2278 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "lowercase                  abbreviations  ability  able  about  above  \\\n",
       "vol                                                                     \n",
       "aeu.ark:/13960/t3126jv35             0.0      0.0   1.0    0.0    0.0   \n",
       "aeu.ark:/13960/t5t72tb3n             1.0      0.0   0.0   42.0   18.0   \n",
       "caia.ark:/13960/t03x9j98z            0.0      0.0   0.0   72.0   67.0   \n",
       "caia.ark:/13960/t13n3fp1h            0.0      1.0   3.0    8.0   11.0   \n",
       "caia.ark:/13960/t2r50x34b            0.0      0.0   0.0   33.0   34.0   \n",
       "\n",
       "lowercase                  accessories  according  account  accurate  \\\n",
       "vol                                                                    \n",
       "aeu.ark:/13960/t3126jv35           0.0        0.0      0.0       0.0   \n",
       "aeu.ark:/13960/t5t72tb3n           0.0        3.0      1.0       0.0   \n",
       "caia.ark:/13960/t03x9j98z          0.0       14.0      0.0       0.0   \n",
       "caia.ark:/13960/t13n3fp1h          0.0        3.0      0.0       0.0   \n",
       "caia.ark:/13960/t2r50x34b          0.0        7.0      0.0       0.0   \n",
       "\n",
       "lowercase                  accurately ...    your  yourself  zigzag  zipper  \\\n",
       "vol                                   ...                                     \n",
       "aeu.ark:/13960/t3126jv35          0.0 ...     0.0       0.0     0.0     0.0   \n",
       "aeu.ark:/13960/t5t72tb3n          0.0 ...    32.0       0.0     0.0     0.0   \n",
       "caia.ark:/13960/t03x9j98z         1.0 ...   181.0       0.0     0.0     0.0   \n",
       "caia.ark:/13960/t13n3fp1h         2.0 ...     3.0       0.0     0.0     0.0   \n",
       "caia.ark:/13960/t2r50x34b         0.0 ...    49.0       0.0     0.0     0.0   \n",
       "\n",
       "lowercase                  zippers  ﬁne  ﬁnish  ﬁnished  ﬁrst  ﬂat  \n",
       "vol                                                                 \n",
       "aeu.ark:/13960/t3126jv35       0.0  0.0    0.0      0.0   0.0  0.0  \n",
       "aeu.ark:/13960/t5t72tb3n       0.0  0.0    0.0      0.0   0.0  0.0  \n",
       "caia.ark:/13960/t03x9j98z      0.0  0.0    0.0      0.0   0.0  0.0  \n",
       "caia.ark:/13960/t13n3fp1h      0.0  0.0    0.0      0.0   0.0  0.0  \n",
       "caia.ark:/13960/t2r50x34b      0.0  0.0    0.0      0.0   0.0  0.0  \n",
       "\n",
       "[5 rows x 2278 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_sums = df.groupby('lowercase')['count'].sum()\n",
    "whitelist = word_sums[(word_sums > 400) & \n",
    "                      word_sums.index.str.isalpha() & \n",
    "                      word_sums.index.str.contains(\"[a-z]\") &\n",
    "                      (word_sums.index.to_series().apply(len) > 2)].index.values\n",
    "\n",
    "filtered_df = df[df.lowercase.isin(whitelist)]\n",
    "wide_df = filtered_df.pivot(index='vol', columns='lowercase', values='count').fillna(0)\n",
    "wide_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volid</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mdp.39015060818443</th>\n",
       "      <td>knit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pst.000016693067</th>\n",
       "      <td>knit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdp.39015056877270</th>\n",
       "      <td>knit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inu.39000004664442</th>\n",
       "      <td>knit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nyp.33433006775112</th>\n",
       "      <td>knit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   label\n",
       "volid                   \n",
       "mdp.39015060818443  knit\n",
       "pst.000016693067    knit\n",
       "mdp.39015056877270  knit\n",
       "inu.39000004664442  knit\n",
       "nyp.33433006775112  knit"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.DataFrame([knitids + sewids,[\"knit\"] * len(knitids) + [\"sew\"] * len(sewids)], index=['volid', 'label']).T.set_index('volid')\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Classifier\n",
    "\n",
    "With the data in this wide format, it can easily be handed to any number of Scikit Learn algorithms. Here, we build a classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomize data for training\n",
    "\n",
    "`sample_labels` aligns the label order with the sample order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = wide_df.sample(frac=1)\n",
    "sample_labels = labels.loc[sample.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(sample[:-10], sample_labels.label[:-10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score the classifier accuracy on 10 held out texts\n",
    "\n",
    "Not a particularly large testing set, this is more as a sanity check. Perfect accuracy is a good sign, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(sample[-10:], sample_labels.label[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What words are 'knitting' vs 'sewing' words?\n",
    "\n",
    "Here, I simply inspect the highest probability words for the two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Knitting words\n",
      "topstitch\tvalance\tfax\toverhanding\tbastings\tunderlining\tfusible\tarmseye\tfastener\tchiffon\themstitching\tinterlining\tbelting\tperforations\tfasteners\tweaves\tnotches\tsnaps\ttailoring\tdrapery\tgingham\tallowances\ttaffeta\tlapped\tbasted\tlayout\tunlined\twaists\tmarkings\tfurnishings\tlinens\tshears\tdraperies\tcording\tplaids\tseamline\tcrisp\twrinkles\tgrades\ttum\tshirring\tinterfacing\tlingerie\ttransparent\toverhand\tupholstery\ttacks\tbutterick\tans\tslash\ttracing\tlaundering\talteration\tenvelope\tchap\truffles\tdressmaker\tstraighten\tmeat\tflounce\tprints\tscrew\tdraft\tnotch\tthimbles\tfaced\tlaundry\tcrotch\tgrain\tglue\tcorded\talterations\tzippers\tfurniture\tstains\tstain\tfat\tpiping\tpar\tdressmaking\ttailored\tpupils\ttailor\teconomics\tdrafting\tsheer\tsnap\tboiling\tquilted\tdamask\tpupil\tpadding\tcorset\ttests\tshuttle\tsinger\tﬁne\tvarieties\tapplying\tlawn\twindows\tcambric\telbow\tplaid\tovercasting\tsugar\tslot\tscalloped\tdull\tlocation\tdust\tsalt\tconnect\tplaits\ttask\tbasting\tblind\tfly\truffle\tslipstitch\n",
      "\n",
      "Sewing words\n",
      "rnd\tyfwd\tbethanne\tribber\ttbl\tfoll\ttto\taran\tssk\tsinker\tcourtney\tpsso\ttay\tsinkers\trem\tamanda\talt\trejoin\telise\tscottie\tpurlwise\tknitter\tshetland\tknitters\tsock\tafghan\tgermantown\tknitwear\tjack\tdivisible\tpurled\tdec\tpurling\tist\tcont\tisle\tcam\treceipt\tinstep\tnarrowing\tinc\tabbreviations\tgarter\tswatch\tfoil\trep\thanks\tcardigan\tmarkers\tscarlet\tdecreases\tguild\trounds\tshells\tshawls\ttreble\treversing\tpatt\tstockinette\tcarriage\tcarrier\tcasting\tsaxony\tpat\tnetting\tspanish\tsixteenth\ttog\tbeg\tseventeenth\tribbing\tridges\ttubular\twhilst\tdecreasing\tmitten\tcommence\tmargaret\those\tpurse\tcolumbia\tspare\tskein\tmoss\tcrafts\tridge\thosiery\tcylinder\ttassels\tskip\tskeins\tply\tmultiple\tballs\tseventh\tcrocheting\tpicot\tsocks\tmittens\tyam\tgerman\todd\twilliam\tmrs\tvol\tobjects\tedition\ttill\tknew\tpicked\tribbed\tstar\tgone\tribs\tmarch\tnorth\twoollen\trelease\twrote\twife\n"
     ]
    }
   ],
   "source": [
    "for i, word in enumerate(['Knitting', 'Sewing']):\n",
    "    print(\"\\n%s words\" % word)\n",
    "    print(\"\\t\".join(pd.Series(clf.feature_log_prob_[i], index=wide_df.columns).sort_values().index.values[:120]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
